{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mgr.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1YugnhnU7WBA46TK_lUPgkS0RM_m6BTzB",
      "authorship_tag": "ABX9TyNLY7jlYOOkTHHjpgpTreci",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuzannazak/MgrSarcasm/blob/master/mgr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-nYxpUDUNZ9"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import csv\n",
        "\n",
        "#Sources:\n",
        "#  https://towardsdatascience.com/tensorflow-sarcasm-detection-in-20-mins-b549311b9e91"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJMq39XG0te"
      },
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "with open('/content/drive/MyDrive/STUDIA/train-balanced.csv', 'r') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        labels.append(row[0])\n",
        "        sentences.append(row[1])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBGht0TxHagU",
        "outputId": "e9d0282e-4449-4d17-e7ee-2d2e6d38f413"
      },
      "source": [
        "print(pd.DataFrame({'sentence' : sentences[0:10], 'label':labels[0:10]}))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            sentence label\n",
            "0                                   Dang dog, thanks     0\n",
            "1  to summon the powers of the flying spaghetti m...     0\n",
            "2       i did that 3rd last 1 by accident last night     0\n",
            "3  He's insane, used him in DC, better than Blake...     0\n",
            "4  Forgot about him, he's a pretty pointless card...     0\n",
            "5                                                hey     0\n",
            "6                                              yeah?     0\n",
            "7                                               okay     0\n",
            "8                                      Condensation?     0\n",
            "9                                What type of juice?     0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaZ9EAOetmPO"
      },
      "source": [
        "# Splitting the dataset into Train and Test\n",
        "training_size = round(len(sentences) * .75)\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUaeISEVgRx1"
      },
      "source": [
        "# Setting tokenizer properties\n",
        "vocab_size = 50000\n",
        "oov_tok = \"<oov>\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdvL9XRgTCT"
      },
      "source": [
        "# Fit the tokenizer on Training data\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etJBM_TlgVVi"
      },
      "source": [
        "# Setting the padding properties\n",
        "max_length = 200\n",
        "trunc_type='post'\n",
        "padding_type='post'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8KSbiMsgXtp"
      },
      "source": [
        "# Creating padded sequences from train and test data\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Kn018hgamY",
        "outputId": "bd54585b-7374-4699-e718-0ad6d0bf536c"
      },
      "source": [
        "# Setting the model parameters\n",
        "embedding_dim = 16\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 200, 16)           800000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 800,433\n",
            "Trainable params: 800,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5MzVyFmgcqj",
        "outputId": "dcca6576-e6b3-4a8a-9acc-89ace9746deb"
      },
      "source": [
        "# Converting the lists to numpy arrays for Tensorflow 2.x\n",
        "training_padded = np.array(training_padded)\n",
        "training_labels = np.array(training_labels, dtype='int32')\n",
        "testing_padded = np.array(testing_padded)\n",
        "testing_labels = np.array(testing_labels, dtype='int32')\n",
        "\n",
        "print(training_padded.dtype)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EgjDrSVHkZG",
        "outputId": "c4f6aa4e-59ec-4d6f-91a7-86efdbafc069"
      },
      "source": [
        "# # Training the model\n",
        "num_epochs = 40\n",
        "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "26384/26384 - 230s - loss: 0.4798 - accuracy: 0.7664 - val_loss: 0.6135 - val_accuracy: 0.6956\n",
            "Epoch 2/40\n",
            "26384/26384 - 232s - loss: 0.4757 - accuracy: 0.7686 - val_loss: 0.6143 - val_accuracy: 0.6984\n",
            "Epoch 3/40\n",
            "26384/26384 - 235s - loss: 0.4717 - accuracy: 0.7715 - val_loss: 0.6148 - val_accuracy: 0.6933\n",
            "Epoch 4/40\n",
            "26384/26384 - 232s - loss: 0.4678 - accuracy: 0.7736 - val_loss: 0.6314 - val_accuracy: 0.6858\n",
            "Epoch 5/40\n",
            "26384/26384 - 228s - loss: 0.4637 - accuracy: 0.7762 - val_loss: 0.6209 - val_accuracy: 0.6944\n",
            "Epoch 6/40\n",
            "26384/26384 - 224s - loss: 0.4597 - accuracy: 0.7786 - val_loss: 0.6293 - val_accuracy: 0.6953\n",
            "Epoch 7/40\n",
            "26384/26384 - 225s - loss: 0.4557 - accuracy: 0.7810 - val_loss: 0.6296 - val_accuracy: 0.6932\n",
            "Epoch 8/40\n",
            "26384/26384 - 226s - loss: 0.4520 - accuracy: 0.7834 - val_loss: 0.6559 - val_accuracy: 0.6852\n",
            "Epoch 9/40\n",
            "26384/26384 - 230s - loss: 0.4483 - accuracy: 0.7856 - val_loss: 0.6390 - val_accuracy: 0.6929\n",
            "Epoch 10/40\n",
            "26384/26384 - 237s - loss: 0.4447 - accuracy: 0.7876 - val_loss: 0.6590 - val_accuracy: 0.6907\n",
            "Epoch 11/40\n",
            "26384/26384 - 237s - loss: 0.4412 - accuracy: 0.7895 - val_loss: 0.6514 - val_accuracy: 0.6908\n",
            "Epoch 12/40\n",
            "26384/26384 - 220s - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.6577 - val_accuracy: 0.6880\n",
            "Epoch 13/40\n",
            "26384/26384 - 222s - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.6636 - val_accuracy: 0.6908\n",
            "Epoch 14/40\n",
            "26384/26384 - 224s - loss: 0.4312 - accuracy: 0.7958 - val_loss: 0.6790 - val_accuracy: 0.6813\n",
            "Epoch 15/40\n",
            "26384/26384 - 222s - loss: 0.4278 - accuracy: 0.7976 - val_loss: 0.6702 - val_accuracy: 0.6906\n",
            "Epoch 16/40\n",
            "26384/26384 - 223s - loss: 0.4248 - accuracy: 0.7994 - val_loss: 0.6862 - val_accuracy: 0.6786\n",
            "Epoch 17/40\n",
            "26384/26384 - 221s - loss: 0.4217 - accuracy: 0.8011 - val_loss: 0.6937 - val_accuracy: 0.6849\n",
            "Epoch 18/40\n",
            "26384/26384 - 227s - loss: 0.4186 - accuracy: 0.8032 - val_loss: 0.6973 - val_accuracy: 0.6815\n",
            "Epoch 19/40\n",
            "26384/26384 - 225s - loss: 0.4159 - accuracy: 0.8045 - val_loss: 0.6974 - val_accuracy: 0.6831\n",
            "Epoch 20/40\n",
            "26384/26384 - 217s - loss: 0.4134 - accuracy: 0.8062 - val_loss: 0.7126 - val_accuracy: 0.6866\n",
            "Epoch 21/40\n",
            "26384/26384 - 217s - loss: 0.4102 - accuracy: 0.8077 - val_loss: 0.7147 - val_accuracy: 0.6824\n",
            "Epoch 22/40\n",
            "26384/26384 - 220s - loss: 0.4077 - accuracy: 0.8092 - val_loss: 0.7089 - val_accuracy: 0.6813\n",
            "Epoch 23/40\n",
            "26384/26384 - 223s - loss: 0.4052 - accuracy: 0.8105 - val_loss: 0.7254 - val_accuracy: 0.6805\n",
            "Epoch 24/40\n",
            "26384/26384 - 220s - loss: 0.4024 - accuracy: 0.8121 - val_loss: 0.7272 - val_accuracy: 0.6813\n",
            "Epoch 25/40\n",
            "26384/26384 - 220s - loss: 0.4002 - accuracy: 0.8135 - val_loss: 0.7304 - val_accuracy: 0.6822\n",
            "Epoch 26/40\n",
            "26384/26384 - 220s - loss: 0.3977 - accuracy: 0.8150 - val_loss: 0.7303 - val_accuracy: 0.6789\n",
            "Epoch 27/40\n",
            "26384/26384 - 220s - loss: 0.3953 - accuracy: 0.8163 - val_loss: 0.7532 - val_accuracy: 0.6752\n",
            "Epoch 28/40\n",
            "26384/26384 - 224s - loss: 0.3928 - accuracy: 0.8178 - val_loss: 0.7610 - val_accuracy: 0.6792\n",
            "Epoch 29/40\n",
            "26384/26384 - 223s - loss: 0.3905 - accuracy: 0.8189 - val_loss: 0.7577 - val_accuracy: 0.6778\n",
            "Epoch 30/40\n",
            "26384/26384 - 223s - loss: 0.3883 - accuracy: 0.8198 - val_loss: 0.7541 - val_accuracy: 0.6755\n",
            "Epoch 31/40\n",
            "26384/26384 - 226s - loss: 0.3863 - accuracy: 0.8214 - val_loss: 0.7718 - val_accuracy: 0.6743\n",
            "Epoch 32/40\n",
            "26384/26384 - 221s - loss: 0.3840 - accuracy: 0.8224 - val_loss: 0.7664 - val_accuracy: 0.6729\n",
            "Epoch 33/40\n",
            "26384/26384 - 219s - loss: 0.3820 - accuracy: 0.8237 - val_loss: 0.7845 - val_accuracy: 0.6746\n",
            "Epoch 34/40\n",
            "26384/26384 - 218s - loss: 0.3799 - accuracy: 0.8251 - val_loss: 0.7891 - val_accuracy: 0.6662\n",
            "Epoch 35/40\n",
            "26384/26384 - 217s - loss: 0.3778 - accuracy: 0.8262 - val_loss: 0.7926 - val_accuracy: 0.6717\n",
            "Epoch 36/40\n",
            "26384/26384 - 218s - loss: 0.3760 - accuracy: 0.8268 - val_loss: 0.7968 - val_accuracy: 0.6716\n",
            "Epoch 37/40\n",
            "26384/26384 - 218s - loss: 0.3738 - accuracy: 0.8285 - val_loss: 0.8005 - val_accuracy: 0.6699\n",
            "Epoch 38/40\n",
            "26384/26384 - 219s - loss: 0.3723 - accuracy: 0.8293 - val_loss: 0.8189 - val_accuracy: 0.6734\n",
            "Epoch 39/40\n",
            "26384/26384 - 218s - loss: 0.3705 - accuracy: 0.8300 - val_loss: 0.8324 - val_accuracy: 0.6595\n",
            "Epoch 40/40\n",
            "26384/26384 - 216s - loss: 0.3686 - accuracy: 0.8309 - val_loss: 0.8166 - val_accuracy: 0.6762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xquPMRFenUW9"
      },
      "source": [
        "sentence = [\"Yes, definitely\",\n",
        "            \"I like cats.\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "print(model.predict(padded))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}